{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7o+un4Tbc9ThskPs1m54J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashfaq-polit/Automation-Codes/blob/main/getColoursFromWeb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "\n",
        "# function to extract html document from given url\n",
        "def getHTMLdocument(url):\n",
        "\n",
        "    # request for HTML document of given url\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if(response.status_code == 200):\n",
        "        # return HTML document\n",
        "        return response.text\n",
        "    else:\n",
        "        # return None\n",
        "        raise Exception(\"Invalid URL or Check your internet connection\")\n",
        "\n",
        "\n",
        "# assign required credentials\n",
        "# assign URL\n",
        "url_to_scrape = input(\"Enter the URL to be Scraped: \")\n",
        "\n",
        "# create document\n",
        "html_document = getHTMLdocument(url_to_scrape)\n",
        "\n",
        "# create soap object\n",
        "soup = BeautifulSoup(html_document, 'html.parser')\n",
        "\n",
        "def getHash(link):\n",
        "    s = ''\n",
        "    i = 0\n",
        "    n = len(link)\n",
        "    while(i < n):\n",
        "        if(link[i] == '#'):\n",
        "            s += link[i:i+7]\n",
        "        i += 1\n",
        "    return s\n",
        "\n",
        "# find all the anchor tags with \"href\"\n",
        "# attribute starting with \"https://\"\n",
        "\n",
        "l = set()\n",
        "\n",
        "for link in soup.find_all('td'):\n",
        "    s = getHash(str(link))\n",
        "    if s != '':\n",
        "        l.add(s.lower())\n",
        "file = open('colors.txt', 'a')\n",
        "file.write('[')\n",
        "for i in l:\n",
        "    file.write(\"'\"+i+\"',\")\n",
        "file.write(']')\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7G3fWIbqGYt",
        "outputId": "abd48110-ef67-4ce1-b359-5691be9d4a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the URL to be Scraped: https://neetcode.io/problems/merge-intervals\n"
          ]
        }
      ]
    }
  ]
}